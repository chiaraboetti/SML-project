{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/lung_training_balanced.csv')\n",
    "test = pd.read_csv('../dataset/lung_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, :-1]\n",
    "test = test.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG..1.</th>\n",
       "      <th>A1CF..29974.</th>\n",
       "      <th>A2M..2.</th>\n",
       "      <th>A2ML1..144568.</th>\n",
       "      <th>A3GALT2..127550.</th>\n",
       "      <th>A4GALT..53947.</th>\n",
       "      <th>A4GNT..51146.</th>\n",
       "      <th>AAAS..8086.</th>\n",
       "      <th>AACS..65985.</th>\n",
       "      <th>AADAC..13.</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWINT..11130.</th>\n",
       "      <th>ZXDA..7789.</th>\n",
       "      <th>ZXDB..158586.</th>\n",
       "      <th>ZXDC..79364.</th>\n",
       "      <th>ZYG11A..440590.</th>\n",
       "      <th>ZYG11B..79699.</th>\n",
       "      <th>ZYX..7791.</th>\n",
       "      <th>ZZEF1..23140.</th>\n",
       "      <th>ZZZ3..26009.</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360222</td>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.043878</td>\n",
       "      <td>0.107509</td>\n",
       "      <td>0.035313</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>0.388106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.107842</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.063209</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856590</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.026746</td>\n",
       "      <td>0.034327</td>\n",
       "      <td>0.088767</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.408058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022699</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.017680</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>0.207112</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>0.032470</td>\n",
       "      <td>0.033668</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.052128</td>\n",
       "      <td>0.096930</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.193605</td>\n",
       "      <td>0.247866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023099</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.030545</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.119782</td>\n",
       "      <td>0.739435</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828164</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.038761</td>\n",
       "      <td>0.099183</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.032050</td>\n",
       "      <td>0.303220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.136453</td>\n",
       "      <td>0.024670</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.094383</td>\n",
       "      <td>0.129190</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>0.320773</td>\n",
       "      <td>0.014914</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458230</td>\n",
       "      <td>0.035763</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.059203</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>0.119531</td>\n",
       "      <td>0.067392</td>\n",
       "      <td>0.027407</td>\n",
       "      <td>0.061682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1BG..1.  A1CF..29974.   A2M..2.  A2ML1..144568.  A3GALT2..127550.  \\\n",
       "0  0.011852      0.014244  0.001433        0.005237          0.058875   \n",
       "1  0.014506      0.107842  0.010356        0.006388          0.063209   \n",
       "2  0.022699      0.058800  0.017680        0.020391          0.030993   \n",
       "3  0.023099      0.016779  0.047539        0.008929          0.030545   \n",
       "4  0.016336      0.136453  0.024670        0.007446          0.094383   \n",
       "\n",
       "   A4GALT..53947.  A4GNT..51146.  AAAS..8086.  AACS..65985.  AADAC..13.  ...  \\\n",
       "0        0.069729       0.013034     0.218439      0.013079    0.009822  ...   \n",
       "1        0.030894       0.015566     0.462745      0.049971    0.017062  ...   \n",
       "2        0.207112       0.021517     0.032470      0.033668    0.034717  ...   \n",
       "3        0.110965       0.017461     0.119782      0.739435    0.013301  ...   \n",
       "4        0.129190       0.029152     0.320773      0.014914    0.036748  ...   \n",
       "\n",
       "   ZWINT..11130.  ZXDA..7789.  ZXDB..158586.  ZXDC..79364.  ZYG11A..440590.  \\\n",
       "0       0.360222     0.013959       0.014200      0.014770         0.043878   \n",
       "1       0.856590     0.035662       0.148649      0.026746         0.034327   \n",
       "2       0.057158     0.044431       0.013567      0.013887         0.052128   \n",
       "3       0.828164     0.018103       0.015658      0.007028         0.038761   \n",
       "4       0.458230     0.035763       0.013237      0.059203         0.058486   \n",
       "\n",
       "   ZYG11B..79699.  ZYX..7791.  ZZEF1..23140.  ZZZ3..26009.  label  \n",
       "0        0.107509    0.035313       0.072556      0.388106      1  \n",
       "1        0.088767    0.010650       0.029632      0.408058      1  \n",
       "2        0.096930    0.024114       0.193605      0.247866      1  \n",
       "3        0.099183    0.008835       0.032050      0.303220      1  \n",
       "4        0.119531    0.067392       0.027407      0.061682      1  \n",
       "\n",
       "[5 rows x 17394 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG..1.</th>\n",
       "      <th>A1CF..29974.</th>\n",
       "      <th>A2M..2.</th>\n",
       "      <th>A2ML1..144568.</th>\n",
       "      <th>A3GALT2..127550.</th>\n",
       "      <th>A4GALT..53947.</th>\n",
       "      <th>A4GNT..51146.</th>\n",
       "      <th>AAAS..8086.</th>\n",
       "      <th>AACS..65985.</th>\n",
       "      <th>AADAC..13.</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWINT..11130.</th>\n",
       "      <th>ZXDA..7789.</th>\n",
       "      <th>ZXDB..158586.</th>\n",
       "      <th>ZXDC..79364.</th>\n",
       "      <th>ZYG11A..440590.</th>\n",
       "      <th>ZYG11B..79699.</th>\n",
       "      <th>ZYX..7791.</th>\n",
       "      <th>ZZEF1..23140.</th>\n",
       "      <th>ZZZ3..26009.</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>0.074668</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>0.174388</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417735</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.410616</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.237540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116891</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.198696</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>0.022898</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960272</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.066350</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.396633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.041548</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.052439</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205466</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.029040</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.037064</td>\n",
       "      <td>0.259274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.136329</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>0.064356</td>\n",
       "      <td>0.084561</td>\n",
       "      <td>0.431292</td>\n",
       "      <td>0.108109</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.193002</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.146196</td>\n",
       "      <td>0.044357</td>\n",
       "      <td>0.136430</td>\n",
       "      <td>0.362707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037482</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>0.122061</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.234959</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804443</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.067084</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.090982</td>\n",
       "      <td>0.048727</td>\n",
       "      <td>0.630893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1BG..1.  A1CF..29974.   A2M..2.  A2ML1..144568.  A3GALT2..127550.  \\\n",
       "0  0.042667      0.050918  0.015425        0.013461          0.025152   \n",
       "1  0.116891      0.016414  0.002584        0.001259          0.006843   \n",
       "2  0.033179      0.009500  0.005520        0.041548          0.072657   \n",
       "3  0.099894      0.136329  0.031623        0.007211          0.030127   \n",
       "4  0.037482      0.042253  0.011060        0.011858          0.051678   \n",
       "\n",
       "   A4GALT..53947.  A4GNT..51146.  AAAS..8086.  AACS..65985.  AADAC..13.  ...  \\\n",
       "0        0.074668       0.037041     0.174388      0.030044    0.033462  ...   \n",
       "1        0.198696       0.002273     0.162922      0.022898    0.004550  ...   \n",
       "2        0.029613       0.019009     0.052439      0.031351    0.022999  ...   \n",
       "3        0.064356       0.084561     0.431292      0.108109    0.013129  ...   \n",
       "4        0.122061       0.010784     0.234959      0.009226    0.021098  ...   \n",
       "\n",
       "   ZWINT..11130.  ZXDA..7789.  ZXDB..158586.  ZXDC..79364.  ZYG11A..440590.  \\\n",
       "0       0.417735     0.029430       0.003645      0.053849         0.118411   \n",
       "1       0.960272     0.011820       0.023760      0.011905         0.008734   \n",
       "2       0.205466     0.018421       0.012871      0.020502         0.009225   \n",
       "3       0.815988     0.009664       0.006521      0.193002         0.034718   \n",
       "4       0.804443     0.014082       0.067084      0.009497         0.008526   \n",
       "\n",
       "   ZYG11B..79699.  ZYX..7791.  ZZEF1..23140.  ZZZ3..26009.  label  \n",
       "0        0.410616    0.034562       0.068021      0.237540      0  \n",
       "1        0.039195    0.066350       0.042229      0.396633      1  \n",
       "2        0.029040    0.008182       0.037064      0.259274      0  \n",
       "3        0.146196    0.044357       0.136430      0.362707      0  \n",
       "4        0.084684    0.090982       0.048727      0.630893      0  \n",
       "\n",
       "[5 rows x 17394 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NN with regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = train.iloc[:,:-1]\n",
    "y = train.iloc[:,-1]\n",
    "test_X = test.iloc[:,:-1]\n",
    "test_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**first model: low depth and width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:48:55.193585: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-20 14:48:55.197122: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-20 14:48:55.333254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.5274 - accuracy: 0.7809\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.4964 - accuracy: 0.7897\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.4784 - accuracy: 0.7897\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.4442 - accuracy: 0.7897\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.3989 - accuracy: 0.7897\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.3448 - accuracy: 0.7996\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.2885 - accuracy: 0.8664\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.2127 - accuracy: 0.9233\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0778 - accuracy: 0.9869\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0541 - accuracy: 0.9923\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 0.9978\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9989\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9989\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 9.5379e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 8.5779e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 7.8435e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 6.9547e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 6.2987e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 5.8155e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 5.1719e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 4.6097e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 4.1244e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 3.8068e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 3.5397e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 3.3138e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 3.0054e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2.8397e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2.6351e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2.3939e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2.2468e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.9970e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.8900e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.7456e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.6117e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.4669e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.4007e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.2976e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.2365e-04 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8447 - accuracy: 0.8683\n",
      "Accuracy: 86.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:49:42.028205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=17393, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=50, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "accuracy = model.evaluate(test_X, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**second model: more width and depth + no regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/92 [..............................] - ETA: 22s - loss: 0.6875 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:49:42.409855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 4s 41ms/step - loss: 0.8294 - accuracy: 0.6922\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4605 - accuracy: 0.8105\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.2168 - accuracy: 0.9211\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.1346 - accuracy: 0.9496\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.0772 - accuracy: 0.9704\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.0430 - accuracy: 0.9847\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.0900 - accuracy: 0.9671\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 7.8438e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 3.9992e-04 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 4.8477e-05 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 2.8698e-05 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 1.3035e-05 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 7.4430e-06 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 4.8925e-06 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 3.4084e-06 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 2.5373e-06 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.9492e-06 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.5322e-06 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.2521e-06 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 1.0413e-06 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 8.6503e-07 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 7.4095e-07 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 6.2601e-07 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 5.6899e-07 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 4.7849e-07 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 4.2238e-07 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 3.7957e-07 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 3.3341e-07 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 2.9975e-07 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 2.6961e-07 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 2.3811e-07 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 2.1667e-07 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 1.9630e-07 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.8200e-07 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 1.6444e-07 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 1.4951e-07 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 1.3784e-07 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 1.2562e-07 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.1621e-07 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 1.0634e-07 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 9.8739e-08 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 9.0503e-08 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 8.3354e-08 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 7.8195e-08 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 7.2131e-08 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 6.7425e-08 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 6.3895e-08 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 5.8375e-08 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 5.4664e-08 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 5.1315e-08 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7712 - accuracy: 0.8732\n",
      "Accuracy: 87.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:52:55.542058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(2000, input_dim=17393, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=50, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "accuracy = model.evaluate(test_X, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**first NN with $l^1$ regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/92 [>.............................] - ETA: 1s - loss: 157164.9219 - accuracy: 0.7200 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:52:55.989126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 11ms/step - loss: 21377.3457 - accuracy: 0.7612\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2612.2939 - accuracy: 0.7897\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2587.1514 - accuracy: 0.7897\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2581.0640 - accuracy: 0.7897\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2579.7000 - accuracy: 0.7897\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2576.7764 - accuracy: 0.7897\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2572.9248 - accuracy: 0.7897\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2571.0061 - accuracy: 0.7897\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2567.6753 - accuracy: 0.7897\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2568.5425 - accuracy: 0.7897\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2563.9861 - accuracy: 0.7897\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2563.9563 - accuracy: 0.7897\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2561.8828 - accuracy: 0.7897\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2555.6328 - accuracy: 0.7897\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2556.4902 - accuracy: 0.7897\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2555.8208 - accuracy: 0.7897\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2552.5742 - accuracy: 0.7897\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2553.1621 - accuracy: 0.7897\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2550.2134 - accuracy: 0.7897\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2549.8271 - accuracy: 0.7897\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2546.5291 - accuracy: 0.7897\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2548.2344 - accuracy: 0.7897\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2547.2095 - accuracy: 0.7897\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2543.2505 - accuracy: 0.7897\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2544.6252 - accuracy: 0.7897\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2541.1406 - accuracy: 0.7897\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 2541.5134 - accuracy: 0.7897\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2540.3533 - accuracy: 0.7897\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2536.0754 - accuracy: 0.7897\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 2538.4414 - accuracy: 0.7897\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2513.8032 - accuracy: 0.8537\n",
      "Accuracy: 85.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:53:25.282782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=17393, activation='relu', \n",
    "    kernel_regularizer=regularizers.l1(100)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=30, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "accuracy = model.evaluate(test_X, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see which input variables are taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NN with dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple and powerful regularization technique for neural networks and deep learning models is dropout.\n",
    "Dropout is a regularization technique for neural network models proposed by Srivastava, et al. in their 2014 paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting (download the PDF).\n",
    "\n",
    "Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.\n",
    "\n",
    "As a neural network learns, neuron weights settle into their context within the network. Weights of neurons are tuned for specific features providing some specialization. Neighboring neurons become to rely on this specialization, which if taken too far can result in a fragile model too specialized to the training data. This reliant on context for a neuron during training is referred to complex co-adaptations.\n",
    "\n",
    "You can imagine that if neurons are randomly dropped out of the network during training, that other neurons will have to step in and handle the representation required to make predictions for the missing neurons. This is believed to result in multiple independent internal representations being learned by the network.\n",
    "\n",
    "The effect is that the network becomes less sensitive to the specific weights of neurons. This in turn results in a network that is capable of better generalization and is less likely to overfit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:53:25.905141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 5s 31ms/step - loss: 291.0627 - accuracy: 0.7897\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 203.7093 - accuracy: 0.7897\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 140.1591 - accuracy: 0.7897\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 92.4623 - accuracy: 0.7897\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 51.6537 - accuracy: 0.7897\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 23.5110 - accuracy: 0.7897\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 7.3289 - accuracy: 0.7897\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.8955 - accuracy: 0.7897\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6436 - accuracy: 0.7897\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6390 - accuracy: 0.7897\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6384 - accuracy: 0.7897\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6393 - accuracy: 0.7897\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6395 - accuracy: 0.7897\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6416 - accuracy: 0.7897\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6380 - accuracy: 0.7897\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6354 - accuracy: 0.7897\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6376 - accuracy: 0.7897\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6342 - accuracy: 0.7897\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6350 - accuracy: 0.7897\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6343 - accuracy: 0.7897\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6339 - accuracy: 0.7897\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6313 - accuracy: 0.7897\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6330 - accuracy: 0.7897\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6335 - accuracy: 0.7897\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6307 - accuracy: 0.7897\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6327 - accuracy: 0.7897\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6300 - accuracy: 0.7897\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6291 - accuracy: 0.7897\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6290 - accuracy: 0.7897\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.6304 - accuracy: 0.7897\n",
      "3/7 [===========>..................] - ETA: 0s - loss: 0.5328 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:54:52.809726: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5198 - accuracy: 0.8537\n",
      "Accuracy: 85.37\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.7, input_shape=(17393,1)))\n",
    "model.add(Dense(12, activation='relu', \n",
    "    kernel_regularizer=regularizers.l1(100)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=30, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "accuracy = model.evaluate(test_X, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NN with permutation importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance techniques were developed to help assuage this interpretability crisis. Feature importance techniques assign a score to each predictor based on its ability to improve predictions. This allows us to rank the predictors in our model based on their relative predictive power.\n",
    "\n",
    "The idea behind feature importance is simple. Inputs that are useful for prediction contain valuable information. If you destroy that information by randomly shuffling the feature values, the quality of your predictions should decrease. If the decrease in quality is small, then the information in the original predictor wasn’t very impactful in determining your predictions — your model is still pretty good without it. Furthermore, if the decrease is large, then the information in the original predictor had a large impact on your predictions.\n",
    "\n",
    "This idea is implemented in three simple steps. Say that you’ve trained an ML model and recorded some measure of quality for the predictions (ex. MSE, log-loss, etc). For each predictor in the dataset:\n",
    "\n",
    "1. Randomly shuffle the data in the predictor while keeping the values of other predictors constant\n",
    "\n",
    "2. Generate new predictions based on the shuffled values and evaluate the quality of your new predictions\n",
    "\n",
    "3. Compute the feature importance score by calculating the decrease in the quality of your new predictions relative to your original predictions\n",
    "\n",
    "Once you’ve computed feature importance scores for all of your features, you can rank them in terms of predictive usefulness. To help explain permutation feature importance more concretely, consider the following synthetic case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
